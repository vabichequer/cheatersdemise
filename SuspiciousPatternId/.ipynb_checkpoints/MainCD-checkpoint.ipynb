{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheaters demise code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous code defined the clusters of suspicious users, which were characterized as those who didn't watch (almost) any videos and documents and got all the answers right. These are thought to be users who deal with fake and real accounts, counting errors on the fakes and taking the right answers on the real ones.\n",
    "\n",
    "Since there is a defined cluster of suspicious users, the following code will try to identify the activity of these users and see if they can be considered as cheaters or not, depending on timing and improvement. By taking into account that timing would be equal to the time difference between an answer from one user and the other, there may be a correlation between them, since after finding the real answer on a fake account, the user would input it into his real account in a short period. Also, improvement is a metric that can differentiate between a user that coincidently did it right after another and a cheater, by measuring if the user got the wrong answer or not. If it did get the wrong answer, than he's not using a fake account.\n",
    "\n",
    "One course of action is to create a graph of exercise (i) by user(j) and the time it took the user to finish it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Import all definitions and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries and definitions loaded correctly.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import Definitions\n",
    "\n",
    "importlib.reload(Definitions)\n",
    "\n",
    "from Definitions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read scores and user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = readDataFile(\"eventos_final.json\")\n",
    "scores_csv = pd.read_csv(\"UAMx_Android301x_1T2015_grade_report_2015-04-21-1145_sanitized.csv\")\n",
    "ids_sospechosos = pd.read_csv(\"UserIDClusterSospechoso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: `item` has been deprecated and will be removed in a future version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished logging scores.\n",
      "Logging exercises...\n",
      "Ended logging.\n"
     ]
    }
   ],
   "source": [
    "N_USERS = len(df.Usuario)\n",
    "\n",
    "# create the exercise listt`\n",
    "correctExercises = np.empty((N_USERS, N_EXERCISES))\n",
    "correctExercises.fill(np.nan)\n",
    "\n",
    "correctExercisesCount = np.empty(N_USERS)\n",
    "correctExercisesCount.fill(0)\n",
    "\n",
    "wrongExercises = np.empty((N_USERS, N_EXERCISES))\n",
    "wrongExercises.fill(np.nan)\n",
    "\n",
    "wrongExercisesCount = np.empty(N_USERS)\n",
    "wrongExercisesCount.fill(0)\n",
    "\n",
    "scores = []\n",
    "\n",
    "print(\"Logging scores...\")\n",
    "\n",
    "for i in range(1, len(df.Usuario)):\n",
    "    try:\n",
    "        score = scores_csv.loc[scores_csv['id'] == int(df.Usuario[i])]['grade'].item()\n",
    "        scores.append((int(df.Usuario[i]), score))\n",
    "    except:                      \n",
    "        scores.append((int(df.Usuario[i]), np.nan))\n",
    "\n",
    "    #clear()\n",
    "    #print('Scores:', math.ceil(i*100/len(df.Usuario)), '% done')\n",
    "\n",
    "print(\"Finished logging scores.\")\n",
    "print(\"Logging exercises...\")\n",
    "\n",
    "for i in range(0, len(df.Usuario)):\n",
    "    for j in range(0, len(df.Eventos[i])):\n",
    "        if (df.Eventos[i][j]['evento'] == 'problem_check'):\n",
    "            #print('\\t problem_check')\n",
    "            if (df.Eventos[i][j]['resultados'] != []):\n",
    "                #print('\\t \\t results')\n",
    "                # convert date time to epoch time for a better comparison\n",
    "                time_split = df.Eventos[i][j]['tiempo'].split('T')\n",
    "                time_tuple = time.strptime(time_split[0] + ' ' + time_split[1][:8], date_format)\n",
    "                time_epoch = time.mktime(time_tuple)   \n",
    "                if(df.Eventos[i][j]['resultados'][0]['correcto'] == 'True'):\n",
    "                    #print('\\t \\t \\t right')\n",
    "                    correctExercises[i][int(df.Eventos[i][j]['id_problema']) - 1] = time_epoch\n",
    "                    correctExercisesCount[i] = correctExercisesCount[i] + 1\n",
    "                elif(df.Eventos[i][j]['resultados'][0]['correcto'] == 'False'):\n",
    "                    #print('\\t \\t \\t wrong')\n",
    "                    wrongExercises[i][int(df.Eventos[i][j]['id_problema']) - 1] = time_epoch\n",
    "                    num_intentos = int(df.Eventos[i][j]['num_intentos'])\n",
    "                    wrongExercisesCount[i] = (wrongExercisesCount[i] - num_intentos + 1) + num_intentos\n",
    "    #clear()\n",
    "    #print('Exercises:', math.ceil(i*100/N_USERS), '% done')\n",
    "\n",
    "print('Ended logging.')\n",
    "\n",
    "N_USERS = len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting down the size of the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7171, 2) (7171, 196) (7171, 196)\n",
      "(3318, 2) (3318, 196) (3318, 196)\n"
     ]
    }
   ],
   "source": [
    "# Cutting down the size of the arrays\n",
    "\n",
    "print(df.shape, correctExercises.shape, wrongExercises.shape)\n",
    "\n",
    "users_to_delete = []\n",
    "\n",
    "for i in range(0, N_USERS):\n",
    "    nbr_attempts = wrongExercisesCount[i] + correctExercisesCount[i]\n",
    "    if (nbr_attempts < MIN_EXERCISES):\n",
    "        df = df.drop([i])\n",
    "        users_to_delete.append(i)\n",
    "\n",
    "correctExercises = np.delete(correctExercises, users_to_delete, 0)\n",
    "wrongExercises = np.delete(wrongExercises, users_to_delete, 0)\n",
    "correctExercisesCount = np.delete(correctExercisesCount, users_to_delete, 0)\n",
    "wrongExercisesCount = np.delete(wrongExercisesCount, users_to_delete, 0)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df.shape, correctExercises.shape, wrongExercises.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_USERS = len(df.Usuario)\n",
    "\n",
    "correctExercises_minutes = correctExercises / 60\n",
    "wrongExercises_minutes = wrongExercises / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump loaded.\n"
     ]
    }
   ],
   "source": [
    "dump_exists = os.path.isfile(str(tol) + '/' + str(tol) + '-' + str(MIN_EXERCISES) + '.csv')\n",
    "\n",
    "if (dump_exists):\n",
    "    df_all_selected_users = pd.read_csv(str(tol) + '/' + str(tol) + '-' + str(MIN_EXERCISES) + '.csv', index_col=0)\n",
    "    df_all_selected_users.fillna('', inplace=True)\n",
    "\n",
    "    selected_users_CC = literal_eval(df_all_selected_users.loc[0][0])\n",
    "    selected_users_XC = literal_eval(df_all_selected_users.loc[1][0])\n",
    "    selected_users_CX = literal_eval(df_all_selected_users.loc[2][0])\n",
    "    selected_users_XX = literal_eval(df_all_selected_users.loc[3][0])\n",
    "    \n",
    "    print('Dump loaded.')\n",
    "else:\n",
    "    #if __name__ == '__main__':\n",
    "        #__spec__ = None\n",
    "        selected_users_CC = Manager().list()\n",
    "        selected_users_XC = Manager().list()\n",
    "        selected_users_CX = Manager().list()\n",
    "        selected_users_XX = Manager().list()\n",
    "\n",
    "        print('Selecting CC users...')\n",
    "        p_CC = Process(target=selectUsers, args=(selected_users_CC, tol, correctExercises_minutes, correctExercises_minutes, 'CC', N_USERS, MIN_EXERCISES,))\n",
    "        p_CC.start()\n",
    "        print('Selecting XC users...')\n",
    "        p_XC = Process(target=selectUsers, args=(selected_users_XC, tol, wrongExercises_minutes, correctExercises_minutes, 'XC', N_USERS, MIN_EXERCISES))\n",
    "        p_XC.start()\n",
    "        print('Selecting CX users...')\n",
    "        p_CX = Process(target=selectUsers, args=(selected_users_CX, tol, correctExercises_minutes, wrongExercises_minutes, 'CX', N_USERS, MIN_EXERCISES))\n",
    "        p_CX.start()\n",
    "        print('Selecting XX users...')\n",
    "        p_XX = Process(target=selectUsers, args=(selected_users_XX, tol, wrongExercises_minutes, wrongExercises_minutes, 'XX', N_USERS, MIN_EXERCISES))\n",
    "        p_XX.start()\n",
    "\n",
    "        p_CC.join()\n",
    "        p_XC.join()\n",
    "        p_CX.join()\n",
    "        p_XX.join()\n",
    "\n",
    "        df_all_selected_users = pd.DataFrame([selected_users_CC, selected_users_XC, selected_users_CX, selected_users_XX])\n",
    "        df_all_selected_users.to_csv(str(tol) + '/' + str(tol) + '-' + str(MIN_EXERCISES) + '.csv')\n",
    "\n",
    "        print(\"Data stored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the time difference between the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time differentiating CC users...\n",
      "Time differentiating XC users...\n",
      "Time differentiating CX users...\n",
      "Time differentiating XX users...\n",
      "XX finished.\n",
      "CX finished.\n",
      "XC finished.\n",
      "CC finished.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    __spec__ = None\n",
    "    time_differences_CC = Manager().list()\n",
    "    time_differences_XC = Manager().list()\n",
    "    time_differences_CX = Manager().list()\n",
    "    time_differences_XX = Manager().list()\n",
    "\n",
    "    print('Time differentiating CC users...')\n",
    "    p_CC = Process(target=ctd.computeTimeDifferences, args=(time_differences_CC, selected_users_CC, \n",
    "                                                        correctExercises_minutes, correctExercises_minutes, 'CC', N_EXERCISES,))\n",
    "    p_CC.start()\n",
    "    print('Time differentiating XC users...')\n",
    "    p_XC = Process(target=ctd.computeTimeDifferences, args=(time_differences_XC, selected_users_XC,\n",
    "                                                        wrongExercises_minutes, correctExercises_minutes, 'XC', N_EXERCISES,))\n",
    "    p_XC.start()\n",
    "    print('Time differentiating CX users...')\n",
    "    p_CX = Process(target=ctd.computeTimeDifferences, args=(time_differences_CX, selected_users_CX,\n",
    "                                                        correctExercises_minutes, wrongExercises_minutes, 'CX', N_EXERCISES,))\n",
    "    p_CX.start()\n",
    "    print('Time differentiating XX users...')\n",
    "    p_XX = Process(target=ctd.computeTimeDifferences, args=(time_differences_XX, selected_users_XX,\n",
    "                                                        wrongExercises_minutes, wrongExercises_minutes, 'XX', N_EXERCISES,))\n",
    "    p_XX.start()\n",
    "\n",
    "    p_CC.join()\n",
    "    p_XC.join()\n",
    "    p_CX.join()\n",
    "    p_XX.join()\n",
    "    \n",
    "    print('Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users in common\n",
    "\n",
    "Finds which users are considered into the selection, without repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Result size: 864\n",
      "\t Result data: [2, 2043, 4, 1876, 2434, 2554, 10, 51, 91, 286, 654, 1359, 1533, 1656, 1676, 2400, 2488, 2613, 3120, 3167, 11, 113, 13, 2408, 19, 1432, 22, 1543, 2098, 2113, 23, 1420, 1490, 24, 1691, 1982, 25, 308, 35, 889, 3072, 40, 567, 1364, 2779, 43, 169, 1206, 1278, 1766, 44, 84, 690, 53, 395, 473, 2723, 68, 515, 1754, 2585, 70, 1102, 77, 1416, 78, 2445, 80, 2036, 82, 2691, 3065, 3317, 83, 2345, 3011, 1988, 2017, 85, 1550, 86, 1100, 2735, 89, 813, 2452, 1392, 1552, 2006, 2231, 2301, 2474, 2889, 94, 362, 2337, 2763, 95, 1149, 98, 120, 836, 1684, 104, 124, 2288, 108, 662, 1674, 3194, 972, 1927, 2478, 115, 555, 808, 902, 1309, 1751, 3122, 3247, 118, 930, 1091, 1738, 1924, 3279, 1588, 2919, 2939, 137, 371, 139, 2555, 2906, 141, 1612, 145, 2528, 148, 979, 2930, 149, 2753, 152, 153, 1730, 154, 989, 157, 1023, 163, 1886, 2070, 2475, 165, 1338, 2153, 175, 174, 2377, 3066, 503, 934, 3062, 3227, 177, 269, 179, 823, 182, 706, 832, 2184, 183, 2563, 187, 1252, 1821, 3301, 195, 1372, 2395, 2823, 3237, 196, 698, 1259, 197, 1670, 1884, 199, 1540, 2436, 201, 1900, 2841, 212, 283, 2306, 222, 2677, 227, 2850, 3117, 3289, 232, 574, 234, 2339, 236, 253, 493, 256, 1107, 828, 1063, 1515, 1922, 2534, 2674, 280, 1047, 1316, 3061, 601, 1919, 1556, 290, 1110, 1984, 3058, 3123, 300, 1650, 3094, 304, 1711, 317, 476, 318, 2041, 324, 550, 1867, 331, 2749, 3148, 338, 1201, 2938, 3107, 342, 2875, 347, 2313, 349, 1753, 351, 1078, 352, 1425, 353, 2419, 357, 361, 1422, 2107, 406, 372, 1150, 377, 981, 398, 1106, 2177, 3174, 401, 1111, 407, 1183, 2519, 2591, 416, 2796, 420, 423, 1494, 3216, 428, 1243, 2549, 432, 436, 3257, 437, 2743, 444, 451, 1517, 2093, 461, 465, 558, 469, 1626, 479, 1516, 2121, 482, 2791, 2913, 485, 1124, 486, 1084, 492, 1797, 2272, 3243, 494, 592, 1999, 496, 1092, 3074, 499, 1119, 500, 502, 799, 1530, 1785, 526, 1847, 2407, 528, 1644, 538, 657, 1428, 544, 2439, 1256, 1305, 551, 562, 1813, 564, 1009, 566, 2046, 2078, 583, 810, 1948, 593, 2671, 598, 1506, 1898, 603, 2057, 2857, 612, 2908, 614, 615, 1116, 617, 2649, 623, 631, 833, 1321, 639, 647, 651, 745, 1498, 2190, 2412, 2882, 1568, 2429, 658, 660, 679, 908, 1094, 3264, 3245, 665, 1695, 668, 984, 3037, 674, 983, 1377, 1819, 2633, 2971, 702, 2056, 703, 714, 2223, 3223, 720, 742, 2230, 722, 1319, 2786, 2966, 724, 1716, 728, 1998, 2609, 739, 1841, 2183, 2916, 749, 2977, 750, 1804, 3173, 753, 1247, 758, 2024, 759, 1829, 762, 1270, 2392, 2604, 764, 2139, 3222, 767, 2776, 774, 1747, 780, 794, 1376, 796, 1021, 2214, 2894, 803, 2033, 804, 805, 2174, 2972, 811, 1621, 2804, 822, 1951, 825, 2570, 829, 861, 903, 940, 2764, 2146, 3012, 2282, 835, 837, 851, 2096, 2240, 2545, 869, 1477, 1075, 1539, 894, 2105, 3206, 897, 910, 1015, 3009, 919, 2805, 928, 1279, 950, 938, 2575, 939, 943, 1696, 945, 1323, 2826, 953, 2413, 956, 1767, 1191, 2712, 976, 2206, 1072, 1123, 990, 1388, 991, 2468, 2961, 993, 1039, 1121, 1439, 1450, 1969, 2114, 2425, 2450, 2569, 1007, 1955, 1008, 1013, 1022, 1138, 1412, 1648, 1801, 3053, 1073, 2864, 2830, 2180, 1085, 1098, 1413, 1109, 1663, 1113, 2019, 2187, 1275, 1707, 1117, 3201, 1566, 2008, 1967, 2090, 2625, 1128, 2954, 1135, 1136, 2390, 3003, 1142, 1148, 3004, 1980, 1154, 1444, 1565, 1873, 1157, 2994, 1160, 1619, 1168, 1740, 1172, 3077, 1175, 1757, 1177, 1185, 1186, 2928, 1193, 1378, 1379, 1572, 2657, 1195, 3095, 1631, 1230, 2965, 1233, 2516, 1234, 2388, 1236, 3220, 1242, 1710, 1248, 1397, 1260, 1654, 1268, 2444, 2198, 1277, 1779, 3160, 1285, 1304, 1307, 2960, 1314, 2561, 3250, 1559, 3275, 1328, 3005, 1333, 3001, 1336, 2275, 1358, 2768, 2210, 2338, 3031, 1385, 2319, 1391, 1590, 1402, 1756, 1862, 1404, 1409, 1415, 2059, 2082, 2087, 1438, 2859, 1509, 1578, 3067, 1455, 2811, 3272, 1456, 2694, 1463, 2246, 1474, 2716, 3313, 1481, 2111, 2248, 1502, 3090, 2058, 2005, 1521, 1526, 1718, 1864, 2851, 1603, 1789, 1547, 3110, 1553, 1555, 3086, 1708, 2690, 2988, 1581, 2964, 1952, 2486, 2265, 2898, 1617, 2748, 2238, 1677, 1808, 1681, 1683, 2332, 3296, 2810, 1719, 3022, 1721, 1858, 3114, 1727, 2789, 1746, 2235, 1750, 1768, 3203, 2606, 2802, 2902, 2305, 1780, 1788, 2108, 1795, 2051, 2594, 1796, 1917, 1800, 2587, 1850, 1863, 1965, 1865, 2666, 1870, 2289, 1902, 2428, 1910, 2612, 2518, 1963, 3271, 1964, 3260, 1979, 2574, 1985, 3121, 2897, 2921, 3132, 2442, 2685, 2054, 2868, 2373, 2459, 2084, 2099, 2627, 2598, 2286, 2750, 2453, 2912, 2131, 2132, 2900, 2141, 2449, 2156, 2158, 2186, 2171, 2812, 2173, 2842, 2197, 2504, 2987, 2217, 2979, 2220, 3239, 2247, 2997, 2267, 2636, 2279, 2294, 3076, 2296, 2678, 2299, 2300, 2995, 2482, 2358, 2370, 3165, 2955, 3295, 2975, 3293, 2447, 2472, 2984, 2822, 2531, 3251, 2558, 2727, 2559, 3158, 2622, 2944, 2624, 3015, 2632, 2755, 2884, 2652, 2656, 2698, 2683, 2878, 2701, 2739, 2947, 2887, 3163, 2813, 3008, 3129, 2844, 3059, 3147, 3104, 412, 425, 2920, 699, 757, 1000, 1176, 1263, 1699, 1311, 1685, 1480, 2149, 2389, 2404, 1729, 415, 610, 2761, 1497, 2067, 1772, 2989, 3089, 2614]\n"
     ]
    }
   ],
   "source": [
    "users_in_common = []\n",
    "\n",
    "for k in range(0, len(selected_users_CC)):\n",
    "    if (selected_users_CC[k][0] not in users_in_common):\n",
    "        users_in_common.append(selected_users_CC[k][0])\n",
    "    if (selected_users_CC[k][1] not in users_in_common):\n",
    "        users_in_common.append(selected_users_CC[k][1]) \n",
    "\n",
    "for l in range(0, len(selected_users_XC)):\n",
    "    if (selected_users_XC[l][0] not in users_in_common):\n",
    "        users_in_common.append(selected_users_XC[l][0])\n",
    "    if (selected_users_XC[l][1] not in users_in_common):\n",
    "        users_in_common.append(selected_users_XC[l][1])\n",
    "\n",
    "for m in range(0, len(selected_users_CX)):\n",
    "    if (selected_users_CX[m][0] not in users_in_common):\n",
    "        users_in_common.append(selected_users_CX[m][0])\n",
    "    if (selected_users_CX[m][1] not in users_in_common):\n",
    "        users_in_common.append(selected_users_CX[m][1]) \n",
    "\n",
    "for n in range(0, len(selected_users_XX)):\n",
    "    if (selected_users_XX[n][0] not in users_in_common):\n",
    "        users_in_common.append(selected_users_XX[n][0])\n",
    "    if (selected_users_XX[n][1] not in users_in_common):\n",
    "        users_in_common.append(selected_users_XX[n][1])\n",
    "\n",
    "print('\\t Result size:', len(users_in_common))\n",
    "print('\\t Result data:', users_in_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join type arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CC', 'XC', 'CX', 'XX']\n",
      "CC 912 || 912\n",
      "XC 27 || 27\n",
      "CX 26 || 26\n",
      "XX 4 || 4\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "all_selected_users = []\n",
    "all_time_differences = []\n",
    "\n",
    "versions = ['CC', 'XC', 'CX', 'XX']\n",
    "temp_users = [list(selected_users_CC), list(selected_users_XC), list(selected_users_CX), list(selected_users_XX)]\n",
    "temp_td = [list(time_differences_CC), list(time_differences_XC), list(time_differences_CX), list(time_differences_XX)]\n",
    "temp_size = [len(selected_users_CC), len(selected_users_XC), len(selected_users_CX), len(selected_users_XX)]\n",
    "\n",
    "#for l in range(0, 4):        \n",
    "#    z = temp_size.index(max(temp_size))\n",
    "#    label.append(versions[z])\n",
    "#    all_selected_users.append(temp_users[z])\n",
    "#    all_time_differences.append(temp_td[z])\n",
    "#    temp_size.pop(z) \n",
    "#    versions.pop(z) \n",
    "#    temp_users.pop(z)\n",
    "#    temp_td.pop(z)\n",
    "\n",
    "all_selected_users = temp_users\n",
    "all_time_differences = temp_td\n",
    "label = versions\n",
    "\n",
    "print(label)\n",
    "print(label[0], len(all_selected_users[0]), '||', len(selected_users_CC))\n",
    "print(label[1], len(all_selected_users[1]), '||', len(selected_users_XC))\n",
    "print(label[2], len(all_selected_users[2]), '||', len(selected_users_CX))\n",
    "print(label[3], len(all_selected_users[3]), '||', len(selected_users_XX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "type_array = type_separation(all_selected_users, all_time_differences, tol)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate user bias and pairs through the type arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "user_pairs, user_score_difference, fig, string_dump, user_interaction_percentages = generate_pairs(type_array, df.Usuario, scores, trimming, label, plot=True)\n",
    "\n",
    "with open('user_bias_dump.txt', 'w') as filehandle:\n",
    "    json.dump(string_dump, filehandle)\n",
    "\n",
    "print('Done.')\n",
    "    \n",
    "#print('Plotting', len(user_pairs), 'pairs consisted of', len(users_in_common), 'users')\n",
    "#fig.set_size_inches(20, len(fig.axes) * 6)\n",
    "#plt.savefig(str(tol) + '/' + str(trimming) + '-user_bias.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_size = len(users_in_common)\n",
    "\n",
    "distance_matrix = np.ones((matrix_size, matrix_size))\n",
    "\n",
    "for i in range(0, matrix_size):\n",
    "    user_1 = users_in_common[i]\n",
    "    for j in range(0, matrix_size):\n",
    "        user_2 = users_in_common[j]\n",
    "        for k in range(0, len(type_array)):\n",
    "            if (type_array[k][0][0] == user_1 and type_array[k][0][1] == user_2):\n",
    "                distance_matrix[i][j] = type_array[k][2]\n",
    "                distance_matrix[j][i] = type_array[k][2]\n",
    "\n",
    "distance_matrix = abs(distance_matrix)\n",
    "\n",
    "for i in range(0, matrix_size):\n",
    "    for j in range(0, matrix_size):\n",
    "        if (i == j):\n",
    "            distance_matrix[i][j] = 0\n",
    "\n",
    "distance_matrix[np.isnan(distance_matrix)] = 1\n",
    "\n",
    "#plt.figure(figsize=(15, 15))\n",
    "#ax = sns.heatmap(distance_matrix, annot=True, annot_kws={\"size\": 7}, fmt = '.2f')\n",
    "\n",
    "#ax.set(xticklabels=users_in_common, yticklabels=users_in_common)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60, 28))  \n",
    "\n",
    "#print(np.shape(distance_matrix))\n",
    "\n",
    "square = ssd.squareform(distance_matrix)\n",
    "\n",
    "linkage = sch.linkage(square, method='single')\n",
    "\n",
    "dend = sch.dendrogram(linkage, labels=users_in_common, leaf_rotation=90)\n",
    "\n",
    "plt.title(\"Dendrogram\", size=40)  \n",
    "plt.xlabel('Users', size=40)\n",
    "plt.ylabel('Distance', size=40)\n",
    "plt.xticks(size = 20)\n",
    "plt.yticks(size = 40)\n",
    "\n",
    "plt.savefig(str(tol) + '/' + str(trimming) + '-dendrogram.png')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process type array and eliminate users without a score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769 pairs remaining.\n"
     ]
    }
   ],
   "source": [
    "type_array = np.array(type_array)\n",
    "user_score_difference = np.array(user_score_difference)\n",
    "\n",
    "total_exercises_under_tol = type_array[:, 3]\n",
    "type_array = np.reshape(type_array[:, 2], (-1, 1))\n",
    "user_score_difference = np.reshape(user_score_difference, (-1, 1))\n",
    "\n",
    "analysing_data = np.concatenate((type_array, user_score_difference), axis=1)\n",
    "\n",
    "analysing_data = np.array(analysing_data, np.float)\n",
    "\n",
    "user_pairs_copy = user_pairs.copy()\n",
    "\n",
    "i = 0\n",
    "while i < len(analysing_data):\n",
    "    if(np.isnan(analysing_data[i,1])):\n",
    "        user_pairs_copy.pop(i)\n",
    "        user_interaction_percentages.pop(i)\n",
    "        user_score_difference = np.delete(user_score_difference, i, 0)\n",
    "        analysing_data = np.delete(analysing_data, i, 0)\n",
    "        total_exercises_under_tol = np.delete(total_exercises_under_tol, i, 0)\n",
    "    else:\n",
    "        i = i + 1\n",
    "\n",
    "print(len(user_pairs_copy), 'pairs remaining.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the amout of exercise by user through the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.xlabel('User bias', fontsize=25)\n",
    "plt.ylabel('Score difference', fontsize=25)\n",
    "plt.title(\"Amount of exercises by user\", fontsize=25)\n",
    "\n",
    "scatter = plt.scatter(analysing_data[:, 0], analysing_data[:, 1], s=250, edgecolors = 'black', c=total_exercises_under_tol, cmap='binary')\n",
    "\n",
    "plt.colorbar(scatter)\n",
    "\n",
    "#for i, txt in enumerate(user_pairs_copy):\n",
    "#    plt.annotate(txt, (analysing_data[i, 0], analysing_data[i, 1]))\n",
    "\n",
    "x = np.linspace(-1, 1, 201)\n",
    "y = [pow(i, 9) for i in x]\n",
    "plt.plot(x, y)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.1, 1.1])\n",
    "axes.set_ylim([-1.1, 1.1])\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "plt.grid(color='grey', linestyle='--', linewidth=.5)\n",
    "\n",
    "plt.savefig(str(tol) + '/' + str(trimming) + '-amount_of_exercises.png', bbox_inches='tight')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the distance from optimal curve (X^9) and separate outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.xlabel('User bias')\n",
    "plt.ylabel('Course final score difference between users')\n",
    "plt.title(\"Distance from optimal curve (X^9)\")\n",
    "\n",
    "normal_points = []\n",
    "outliers = []\n",
    "\n",
    "for i, txt in enumerate(analysing_data):\n",
    "    dist = distance(analysing_data[i, 0], analysing_data[i, 1])\n",
    "    if (dist > 0.25):\n",
    "        plt.annotate(round(dist, 2), (analysing_data[i, 0], analysing_data[i, 1])) \n",
    "        outliers.append([analysing_data[i, 0], analysing_data[i, 1], user_pairs_copy[i][0], user_pairs_copy[i][1]])\n",
    "    else:\n",
    "        normal_points.append([analysing_data[i, 0], analysing_data[i, 1], user_pairs_copy[i][0], user_pairs_copy[i][1]])\n",
    "\n",
    "#for i, txt in enumerate(user_pairs_copy):\n",
    "#    plt.annotate(txt, (analysing_data[i, 0], analysing_data[i, 1]))\n",
    "\n",
    "normal_points = np.asarray(normal_points)\n",
    "outliers = np.asarray(outliers)\n",
    "\n",
    "plt.scatter(normal_points[:, 0], normal_points[:, 1], marker='o', color='blue', picker=True)   \n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], marker='o', color='red', picker=True)    \n",
    "\n",
    "x = np.linspace(-1, 1, 201)\n",
    "y = [pow(i, 9) for i in x]\n",
    "plt.plot(x, y)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.1, 1.1])\n",
    "axes.set_ylim([-1.1, 1.1])\n",
    "\n",
    "plt.grid(color='grey', linestyle='--', linewidth=.5)\n",
    "\n",
    "plt.savefig(str(tol) + '/' + str(trimming) + '-distance_from_curve.png')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking users: outliers or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG = 'both'\n",
    "\n",
    "if (FLAG == 'outliers'):\n",
    "    array_being_analysed = outliers\n",
    "if (FLAG == 'normals'):\n",
    "    array_being_analysed = normal_points\n",
    "else:\n",
    "    array_being_analysed = np.concatenate((normal_points, outliers), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the hypotheses regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = []\n",
    "second = []\n",
    "third = []\n",
    "fourth = []\n",
    "fifth = []\n",
    "others = []\n",
    "\n",
    "plt.figure(figsize=(11, 7))\n",
    "plt.xlabel('User bias', fontsize=25)\n",
    "plt.ylabel('Score difference', fontsize=25)\n",
    "plt.title(\"Hypotheses\", fontsize=25)\n",
    "\n",
    "for i in range(0, len(array_being_analysed)):\n",
    "    d = array_being_analysed[i, 0]\n",
    "    sc = array_being_analysed[i, 1]\n",
    "\n",
    "    if (d >= 0.5 and sc >= 0.25):\n",
    "        first.append([d, sc])\n",
    "    elif (d >= 0.5 and sc > -0.25 and sc < 0.25):\n",
    "        second.append([d, sc])\n",
    "    elif (d > -0.5 and d < 0.5 and sc > -0.25 and sc < 0.25):\n",
    "        third.append([d, sc])\n",
    "    elif (d <= -0.5 and sc > -0.25 and sc < 0.25):\n",
    "        fourth.append([d, sc])\n",
    "    elif (d <= -0.5 and sc <= -0.25):\n",
    "        fifth.append([d, sc])\n",
    "    else:\n",
    "        others.append([d, sc])\n",
    "\n",
    "first = np.asarray(first)\n",
    "second = np.asarray(second)\n",
    "third = np.asarray(third)\n",
    "fourth = np.asarray(fourth)\n",
    "fifth = np.asarray(fifth)\n",
    "others = np.asarray(others)\n",
    "\n",
    "plt.scatter(first[:, 0], first[:, 1], marker='o', color='blue', s=250, picker=True)\n",
    "plt.scatter(second[:, 0], second[:, 1], marker='o', color='black', s=250, picker=True)\n",
    "plt.scatter(third[:, 0], third[:, 1], marker='o', color='black', s=250, picker=True)\n",
    "plt.scatter(fourth[:, 0], fourth[:, 1], marker='o', color='black', s=250, picker=True)\n",
    "plt.scatter(fifth[:, 0], fifth[:, 1], marker='o', color='orange', s=250, picker=True)\n",
    "plt.scatter(others[:, 0], others[:, 1], marker='o', color='grey', s=250, picker=True)\n",
    "\n",
    "x = np.linspace(-1, 1, 201)\n",
    "y = [pow(i, 9) for i in x]\n",
    "plt.plot(x, y)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.1, 1.1])\n",
    "axes.set_ylim([-1.1, 1.1])\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.grid(color='grey', linestyle='--', linewidth=.5)\n",
    "\n",
    "plt.savefig(str(tol) + '/' + str(trimming) + '-hypotheses.png', bbox_inches='tight')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ip_addrs = check_ip_addresses(array_being_analysed, df)\n",
    "\n",
    "ips_in_common = []\n",
    "\n",
    "for i in range(0, len(ip_addrs)):\n",
    "    user_1_ips = ip_addrs[i][0]\n",
    "    user_2_ips = ip_addrs[i][1]\n",
    "    count_1 = ip_addrs[i][2]\n",
    "    count_2 = ip_addrs[i][3]\n",
    "    amount = 0\n",
    "    for j in range(0, len(user_1_ips)):\n",
    "        for k in range(0, len(user_2_ips)):\n",
    "            if ((user_1_ips[j] == user_2_ips[k]) == True):\n",
    "                amount = amount + min(count_1[j], count_2[k])\n",
    "    #print('-'*100)\n",
    "    #print('User 1 (', array_being_analysed[i][2], ',', len(user_1_ips), '): ', user_1_ips, count_1)\n",
    "    #print('User 2 (', array_being_analysed[i][3], ',', len(user_2_ips), '): ', user_2_ips, count_2)\n",
    "    #print('\\nCorrelation: ', amount, np.intersect1d(user_1_ips, user_2_ips, assume_unique=True))\n",
    "    ips_in_common.append(amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot checked users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.xlabel('User bias', fontsize=25)\n",
    "plt.ylabel('Course final score difference between users', fontsize=25)\n",
    "plt.title(\"Exercises with the same IP\", fontsize=25)\n",
    "\n",
    "scatter = plt.scatter(array_being_analysed[:, 0], array_being_analysed[:, 1], edgecolors = 'black', c=ips_in_common, cmap='binary')\n",
    "\n",
    "plt.colorbar(scatter)\n",
    "\n",
    "#for i, txt in enumerate(ips_in_common):\n",
    "    #plt.annotate((txt, (array_being_analysed[i, 2], array_being_analysed[i, 3])), (array_being_analysed[i, 0], array_being_analysed[i, 1]))\n",
    "\n",
    "x = np.linspace(-1, 1, 201)\n",
    "y = [pow(i, 9) for i in x]\n",
    "plt.plot(x, y)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.1, 1.1])\n",
    "axes.set_ylim([-1.1, 1.1])\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "plt.grid(color='grey', linestyle='--', linewidth=.5)\n",
    "\n",
    "plt.savefig(str(tol) + '/' + str(trimming) + '-exercises_same_ip-' + FLAG + '.png')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the material usage index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By counting the number of events a user has, it can measure how many of them were directed towards reading the materials. This is done by dividing the count of all the events by the count of the events where the user tried to solve an exercise. However, since a user can try the same exercise multiple times, it was decided that if the user tried the exercise at least one time (be it right or wrong), then it would count as a material usage towards that exercise and that's it, no additional tries for that exercise would be considered as material usage.\n",
    "\n",
    "Therefore, the formula is: number_of_exercises_tried / (number_of_material_usages + number_of_exercises_tried).\n",
    "\n",
    "The results mean: \n",
    "1 -> purely exercise tryouts (fake account); \n",
    "\n",
    "0,5 -> equal number of exercise tryouts and material reviews (legit user) and; \n",
    "\n",
    "0 -> purely material reviews (probably a professor or a material thief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "material_usage = check_material_usage(array_being_analysed, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xlabel('User bias', fontsize=25)\n",
    "plt.ylabel('Score difference', fontsize=25)\n",
    "plt.title(\"mMIR\", fontsize=25)\n",
    "\n",
    "material_usage_str = []\n",
    "\n",
    "for i in range(0, len(material_usage)):\n",
    "    material_usage_str.append(str(min(round(material_usage[i, 0], 2), round(material_usage[i, 1], 2))))\n",
    "\n",
    "c_intensities = []\n",
    "\n",
    "for i in range(0, len(array_being_analysed)):\n",
    "    c_intensities.append(min(material_usage[i, 0], material_usage[i, 1]))\n",
    "    \n",
    "scatter = plt.scatter(array_being_analysed[:, 0], array_being_analysed[:, 1], s=250, edgecolors = 'black', c=c_intensities, cmap='binary')\n",
    "\n",
    "plt.colorbar(scatter)\n",
    "\n",
    "material_usage_dump = []\n",
    "\n",
    "for i, txt in enumerate(material_usage_str):\n",
    "    #plt.annotate((txt, (array_being_analysed[i, 2], array_being_analysed[i, 3])), (array_being_analysed[i, 0], array_being_analysed[i, 1]))\n",
    "    material_usage_dump.append('User: ' + str(array_being_analysed[i, 2]) + ' User: ' + str(array_being_analysed[i, 3]) + ' ' + txt)\n",
    "\n",
    "with open('material_usage_dump-' + FLAG + '.txt', 'w') as filehandle:\n",
    "    json.dump(material_usage_dump, filehandle)\n",
    "\n",
    "x = np.linspace(-1, 1, 201)\n",
    "y = [pow(i, 9) for i in x]\n",
    "plt.plot(x, y)\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.1, 1.1])\n",
    "axes.set_ylim([-1.1, 1.1])\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "plt.grid(color='grey', linestyle='--', linewidth=.5)\n",
    "\n",
    "plt.savefig(str(tol) + '/' + str(trimming) + '-material_usage_index-' + FLAG + '.png', bbox_inches='tight')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a connection graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_addrs_list = []\n",
    "\n",
    "ip_addrs_list.append(check_ip_addresses(normal_points, df))\n",
    "ip_addrs_list.append(check_ip_addresses(outliers, df))\n",
    "\n",
    "temp = []\n",
    "\n",
    "labels_ip_both = []\n",
    "\n",
    "for h in range(0, 2):\n",
    "    ip_addrs = ip_addrs_list[h]\n",
    "    for i in range(0, len(ip_addrs)):\n",
    "        user_1_ips = ip_addrs[i][0]\n",
    "        user_2_ips = ip_addrs[i][1]\n",
    "        count_1 = ip_addrs[i][2]\n",
    "        count_2 = ip_addrs[i][3]\n",
    "        amount = 0\n",
    "        for j in range(0, len(user_1_ips)):\n",
    "            for k in range(0, len(user_2_ips)):\n",
    "                if ((user_1_ips[j] == user_2_ips[k]) == True):\n",
    "                    amount = amount + min(count_1[j], count_2[k])\n",
    "        #print('User 1 (', array_being_analysed[i][2], ',', len(user_1_ips), '): ', user_1_ips, count_1)\n",
    "        #print('User 2 (', array_being_analysed[i][3], ',', len(user_2_ips), '): ', user_2_ips, count_2)\n",
    "        #print('\\nCorrelation: ', amount, np.intersect1d(user_1_ips, user_2_ips, assume_unique=True))\n",
    "        temp.append('/' + str(len(user_1_ips)) + '/' + str(len(user_2_ips)) + '/' + str(len(np.intersect1d(user_1_ips, user_2_ips, assume_unique=True))))\n",
    "    labels_ip_both.append(temp)\n",
    "    \n",
    "G = nx.DiGraph()\n",
    "\n",
    "user_bias_array = analysing_data[:, 0]\n",
    "\n",
    "labels_ip = []\n",
    "i = 0\n",
    "\n",
    "material_usage = []\n",
    "material_usage_both = []\n",
    "material_usage_both.append(check_material_usage(normal_points, df))\n",
    "material_usage_both.append(check_material_usage(outliers, df))  \n",
    "\n",
    "while i < len(user_pairs_copy):\n",
    "    user_1 = int(user_pairs_copy[i][0])\n",
    "    user_2 = int(user_pairs_copy[i][1])\n",
    "    found = False\n",
    "\n",
    "    for j in range(0, len(normal_points)):\n",
    "        if (user_1 == normal_points[j][2] and user_2 == normal_points[j][3]):\n",
    "            labels_ip.append(labels_ip_both[0][j])\n",
    "            material_usage.append(material_usage_both[0][j])\n",
    "            found = True\n",
    "            i = i + 1\n",
    "            break\n",
    "\n",
    "    if (not found):   \n",
    "        for k in range(0, len(outliers)):\n",
    "            if (user_1 == outliers[k][2] and user_2 == outliers[k][3]):\n",
    "                labels_ip.append(labels_ip_both[1][k])\n",
    "                material_usage.append(material_usage_both[1][k])\n",
    "                i = i + 1\n",
    "                break\n",
    "\n",
    "node_colors = {}\n",
    "\n",
    "for i in range(0, len(material_usage)):           \n",
    "    user_1 = int(user_pairs_copy[i][0])\n",
    "    user_2 = int(user_pairs_copy[i][1])\n",
    "    if (material_usage[i][0] == 0):\n",
    "        node_colors[user_1] = 'red'\n",
    "    else:\n",
    "        node_colors[user_1] = 'blue'\n",
    "    if (material_usage[i][1] == 0):\n",
    "        node_colors[user_2] = 'red'\n",
    "    else:\n",
    "        node_colors[user_2] = 'blue'\n",
    "\n",
    "node_color_array = []\n",
    "\n",
    "labels = {}\n",
    "\n",
    "for i in range(0, len(user_pairs_copy)):\n",
    "    user_1 = int(user_pairs_copy[i][0])\n",
    "    user_2 = int(user_pairs_copy[i][1])\n",
    "    G.add_node(user_1)\n",
    "    G.add_node(user_2)\n",
    "\n",
    "    temp = abs(round(user_bias_array[i], 2))\n",
    "\n",
    "    if (user_bias_array[i] >= 0):\n",
    "        G.add_edge(user_1, user_2, width=temp * 10)\n",
    "        labels[user_1, user_2] = str(temp) + str(labels_ip[i])\n",
    "    else:\n",
    "        G.add_edge(user_2, user_1, width=temp * 10)\n",
    "        labels[user_2, user_1] = str(temp) + str(labels_ip[i])\n",
    "\n",
    "for node in G:\n",
    "    node_color_array.append(node_colors[node])\n",
    "\n",
    "pos = nx.nx_agraph.graphviz_layout(G, prog='dot', args=\"-Gnodesep=5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot connection graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 50))\n",
    "\n",
    "width = [G[u][v]['width'] for u,v in G.edges()]      \n",
    "\n",
    "nx.draw(G, pos, node_color=node_color_array)\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, width=width)\n",
    "\n",
    "nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "\n",
    "text = nx.draw_networkx_edge_labels(G, pos, edge_labels=labels, font_color='red')\n",
    "\n",
    "for _,t in text.items():\n",
    "    t.set_rotation('vertical')\n",
    "\n",
    "plt.savefig(str(tol) + '/' + str(trimming) + '-connection-graph' + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "for i, txt in enumerate(analysing_data):\n",
    "    temp.append([analysing_data[i, 0], analysing_data[i, 1], user_pairs_copy[i][0], user_pairs_copy[i][1]])\n",
    "\n",
    "ip_addrs_temp = check_ip_addresses(temp, df)\n",
    "\n",
    "ips_in_common_temp = []\n",
    "\n",
    "for i in range(0, len(ip_addrs_temp)):\n",
    "    user_1_ips = ip_addrs_temp[i][0]\n",
    "    user_2_ips = ip_addrs_temp[i][1]\n",
    "    amount = 0\n",
    "    for j in range(0, len(user_1_ips)):\n",
    "        for k in range(0, len(user_2_ips)):\n",
    "            if (user_1_ips[j] == user_2_ips[k]):\n",
    "                amount = amount + 1\n",
    "    print('Total:', len(user_1_ips), len(user_2_ips), amount)\n",
    "    #print('-'*100)\n",
    "    #print('User 1 (', array_being_analysed[i][2], ',', len(user_1_ips), '): ', user_1_ips, count_1)\n",
    "    #print('User 2 (', array_being_analysed[i][3], ',', len(user_2_ips), '): ', user_2_ips, count_2)\n",
    "    #print('\\nCorrelation: ', amount, np.intersect1d(user_1_ips, user_2_ips, assume_unique=True))\n",
    "    total = len(user_1_ips) + len(user_2_ips)\n",
    "    ips_in_common_temp.append(amount / (total - amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uip = np.asarray(user_interaction_percentages)\n",
    "mu = np.asarray(material_usage)\n",
    "\n",
    "CC = uip[:, 0]\n",
    "XC = uip[:, 1]\n",
    "XX = uip[:, 2]\n",
    "MIR = [min(pair[0], pair[1]) for pair in mu]\n",
    "ScoreDif = abs(user_score_difference[:, 0])\n",
    "#IPs = np.asarray([i / j  for i, j in zip(ips_in_common_temp, total_exercises_under_tol)])\n",
    "IPs = np.asarray(ips_in_common_temp)\n",
    "UB = user_bias_array\n",
    "#TE = total_exercises_under_tol\n",
    "\n",
    "MIR = np.asarray(MIR)\n",
    "\n",
    "dict_var = {'CC':CC, 'XC':XC, 'XX':XX, 'User Bias':UB, 'Minimal MIR':MIR, 'Score Diff':ScoreDif, \n",
    "            'IPs in common':IPs}\n",
    "\n",
    "for key, value in dict_var.items():\n",
    "    print(key, len(value), value.shape)\n",
    "    \n",
    "x = pd.DataFrame.from_dict(dict_var)\n",
    "\n",
    "# Get column names first\n",
    "names = x.columns\n",
    "# Create the Scaler object\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Fit your data on the scaler object\n",
    "scaled_x = scaler.fit_transform(x)\n",
    "scaled_x = pd.DataFrame(scaled_x, columns=names)\n",
    "\n",
    "x.index = user_pairs_copy\n",
    "\n",
    "pd.set_option('display.max_rows', len(x))\n",
    "#x.drop(x.tail(1).index,inplace=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation=scaled_x.corr() #Correlation Matrix\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x.pop('XC')\n",
    "x.pop('XC')\n",
    "scaled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "\n",
    "kmeans.fit_predict(scaled_x)\n",
    "\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x['Labels'] = kmeans.labels_\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = plt.scatter(array_being_analysed[:, 0], array_being_analysed[:, 1], edgecolors = 'black', c=kmeans.labels_, cmap='binary')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(str(tol) + '/' + str(trimming) + '-clustering' + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "harvester = len(kmeans.labels_[kmeans.labels_ == 0]) \n",
    "person = len(kmeans.labels_[kmeans.labels_ == 1]) \n",
    "\n",
    "print('In this dataset, there are', harvester, 'harvester type copies and', person, 'person type copies.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", len(x['Labels'][x['Labels'] == 1]), \"1's and\", len(x['Labels'][x['Labels'] == 0]), \"0's as labels.\")\n",
    "prop_1 = len(x['Labels'][x['Labels'] == 1]) / len(x['Labels'])\n",
    "prop_0 = len(x['Labels'][x['Labels'] == 0]) / len(x['Labels'])\n",
    "print(\"The proportion of 1's and 0's is, repectively:\", prop_1, prop_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class_weights = {}\n",
    "class_weights[0] = prop_0\n",
    "class_weights[1] = prop_1\n",
    "\n",
    "print(class_weights)\n",
    "\n",
    "NUM_CV = 10\n",
    "\n",
    "X = scaled_x\n",
    "y = x['Labels']\n",
    "\n",
    "C = np.linspace(-5, 11, 9)\n",
    "C = [pow(2, i) for i in C]\n",
    "gamma = np.linspace(-1, 15, 9)\n",
    "gamma = [pow(2, i) for i in gamma]\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": C,  #2^[-5, -3, ... , 10]\n",
    "          \"gamma\": gamma} #2^[-1, 1, ... , 15]\n",
    "\n",
    "svc = svm.SVC(kernel='linear', class_weight=class_weights)\n",
    "clf = GridSearchCV(svc, param_grid=p_grid, cv=NUM_CV, iid=False)\n",
    "print(clf)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=NUM_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This model can differentiate harvesters (0) from collaborators (1) with an accuracy and standard \\\n",
    "deviation of, respectively: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 5, 10])\n",
    "y = np.power([0.98, 0.97, 0.99, 0.99]) # Effectively y = x**2\n",
    "e = np.array([0.1, 0.1, 0.05, 0.01])\n",
    "\n",
    "plt.errorbar(x, y, e, linestyle='None', marker='^')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
